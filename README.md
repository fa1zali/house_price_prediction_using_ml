### Date created
17th Sep 2022

### Project Title
**House Price Prediction using XGBoost Regressor**

### Description
Gradient boosting refers to a class of ensemble machine learning algorithms that can be used for classification or regression predictive modeling problems.

Ensembles are constructed from decision tree models. Trees are added one at a time to the ensemble and fit to correct the prediction errors made by prior models. This is a type of ensemble machine learning model referred to as boosting.

Models are fit using any arbitrary differentiable loss function and gradient descent optimization algorithm. This gives the technique its name, “gradient boosting,” as the loss gradient is minimized as the model is fit, much like a neural network.

For this project, we will be building a machine learning model to predict the price of a *House* based on certain features included in the dataset. Our goal is to work through this notebook by collecting data, preprocessing it, splitting it into testing and training datasets, train the model and evaluate the accuracy of our model.

### Files used
We used the following dataset available through the Scikit Learn library to work on this project:

* [Boston Housing Prices Dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html)

### Credits
Thanks to Kaggle for teaching me ML :sparkles: :heart: :sparkles:
